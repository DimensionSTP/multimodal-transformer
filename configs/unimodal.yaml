# @package _global_
defaults:
  - dataset: audio_kemdy19_dataset
  - training_arguments: training_arguments
  - hydra: hydra

package_name: multimodal-transformer
project_dir: /home/ddang/${package_name}
connected_dir: /data/${package_name}

seed: 2024

num_labels: 7

split:
  train: train
  val: val
  test: test

batch_size: 32

audio_pretrained_model_name: facebook/hubert-large-ls960-ft
text_pretrained_model_name: klue/roberta-large

output_hidden_states: False

metric:
  first_metric: glue
  second_metric: mnli

lr: 0.00002

epoch: 5

model_name: UniModalTransformer
dataset_name: KEMDy19
mode: audio

project_name: ${model_name}-${dataset_name}-${mode}
save_detail: bs${batch_size}-lr${lr}-epoch${epoch}

run_name: ${project_name}
work_dir: ${hydra:runtime.cwd}

output_directory: ${connected_dir}/checkpoints/${mode}
save_predictions: ${connected_dir}/preds/unimodal